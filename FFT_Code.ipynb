{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saisumedha/Deep-Learning-based-approach-for-Cardiovascular-Monitoring-Using-Seismocardiogram-Signals/blob/main/FFT_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cem7L7F-6SiB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbf87ff5-8d73-4b0b-cb0a-2f3c077cb3e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.7.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "O_CFmfRUUMks",
        "outputId": "2c8a4a4b-2424-4a8e-fe09-013f6f9b761b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'KerasLazyLoader' from 'tensorflow.python.util.lazy_loader' (/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/lazy_loader.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-53968207222e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_KerasLazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'KerasLazyLoader' from 'tensorflow.python.util.lazy_loader' (/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/lazy_loader.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71TTGDer6Dko"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import LayerNormalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qW_tZJ9dIu-_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVJfPhRdzJsT"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.python.client import device_lib\n",
        "# print(device_lib.list_local_devices())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ummp5mKUOnWg"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPbxcQZxpDsW"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "!pip install --upgrade keras\n",
        "!pip install --upgrade tensorflow\n",
        "!pip install -U tensorflow\n",
        "!python -m pip show tensorflow\n",
        "!pip install --upgrade tensorflow\n",
        "!python -m pip show tensorflow\n",
        "!pip install tensorflow-addons\n",
        "!pip install -q tensorflow-addons\n",
        "!pip install --upgrade tensorflow\n",
        "!pip install utils\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtGrwIAvPScX"
      },
      "outputs": [],
      "source": [
        "!pip install pyedflib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gx3C2Z7jPs0P"
      },
      "outputs": [],
      "source": [
        "!pip install padasip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gjVM6_7QNoH"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.12;Â keras==2.12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tg7QWhwQTZU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"True\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1VOk7-c5xF5"
      },
      "outputs": [],
      "source": [
        "fileNames = []\n",
        "fileName_str = []\n",
        "#Change the number here to read different files\n",
        "for i in range(10,11,1):\n",
        "  name_str = ''\n",
        "  if(i<10):\n",
        "    name_str = 'b00'\n",
        "  else:\n",
        "    name_str = 'b0'\n",
        "  fileNames.append(name_str+ str(i)+'.edf')\n",
        "  fileName_str.append(name_str+ str(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OjZGW0ABl60"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, filtfilt, find_peaks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_TPhcggPIG5"
      },
      "outputs": [],
      "source": [
        "import pyedflib\n",
        "import numpy as np\n",
        "from scipy import signal\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.decomposition import FastICA\n",
        "from sklearn.preprocessing import scale\n",
        "import padasip as pa\n",
        "from scipy import signal\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from keras.layers import LeakyReLU\n",
        "original_scg = []\n",
        "original_ecg = []\n",
        "class DataUtils:\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.fileNames = fileNames\n",
        "\n",
        "\n",
        "    # def readData(self, sigNum, path=\"/content/drive/MyDrive/Colab Notebooks/basal/\"):\n",
        "    def readData(self, sigNum, path=\"/content/drive/MyDrive/drive-download-20230428T081947Z-001/\"):\n",
        "        file_name = path + self.fileNames[sigNum]\n",
        "        #print(file_name)\n",
        "        #file_name =  self.fileNames[sigNum]\n",
        "        f = pyedflib.EdfReader(file_name)\n",
        "        n = f.signals_in_file\n",
        "        signal_labels = f.getSignalLabels()\n",
        "        print(\"Reading file:: \",file_name)\n",
        "        print(\"different columns:: \",signal_labels)\n",
        "        print(\"total number of samples\",f.getNSamples())\n",
        "        abdECG = np.zeros((1, f.getNSamples()[0]))\n",
        "        scg = np.zeros((1, f.getNSamples()[0]))\n",
        "        scg[0, :] = f.readSignal(3)\n",
        "        scg = scale(scg, axis=1)\n",
        "        #scg[0, :] = scale(self.butter_bandpass_filter(scg, 1, 200, 1000), axis=1)\n",
        "        #for i in np.arange(0, n-2):\n",
        "        abdECG[0, :] = f.readSignal(0)\n",
        "        abdECG = scale(abdECG, axis=1)\n",
        "        #abdECG = scale(self.butter_bandpass_filter(abdECG, 1, 110, 1000), axis=1)\n",
        "        print(\"before downsampling\",abdECG.shape[1])\n",
        "        abdECG = signal.resample(abdECG, int(abdECG.shape[1] / 5), axis=1)\n",
        "        scg = signal.resample(scg, int(scg.shape[1] / 5), axis=1)\n",
        "\n",
        "        # # differencing code starts\n",
        "        # scg = np.diff(scg)\n",
        "        # abdECG = np.diff(abdECG)\n",
        "        # # differencing code ends\n",
        "\n",
        "        print(\"after downsampling\",abdECG.shape[1])\n",
        "        '''function for ecg identification, using pan-tompkins algorithm'''\n",
        "        fs = []\n",
        "        fs.append(f.getSampleFrequency(0))\n",
        "\n",
        "        #changed the return sequence, so that converion will be from SCG to ECG\n",
        "        return  scg, abdECG, fs\n",
        "\n",
        "    def windowingSig(self, sig1, sig2, windowSize=15):\n",
        "        signalLen = sig2.shape[1]\n",
        "        signalsWindow1 = [sig1[:, int(i):int(i + windowSize)].transpose() for i in range(0, signalLen - windowSize, windowSize)]\n",
        "        signalsWindow2 = [sig2[:, int(i):int(i + windowSize)].transpose() for i in range(0, signalLen - windowSize, windowSize)]\n",
        "        print(\"SCG shape after windowing:: \",np.array(signalsWindow1).shape)\n",
        "        print(\"ECG shape after windowing:: \",np.array(signalsWindow2).shape)\n",
        "\n",
        "        return signalsWindow1, signalsWindow2\n",
        "\n",
        "    def adaptFilterOnSig(self, src, ref):\n",
        "        f = pa.filters.FilterNLMS(n=4, mu=0.1, w=\"random\")\n",
        "        for index, sig in enumerate(src):\n",
        "            try:\n",
        "                y, e, w = f.run(ref[index][:, 0], sig)\n",
        "                ref[index][:, 0] = e\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        return ref\n",
        "\n",
        "    def calculateICA(self, sdSig, component=7):\n",
        "        ica = FastICA(n_components=component, max_iter=1000)\n",
        "        icaRes = []\n",
        "        for index, sig in enumerate(sdSig):\n",
        "            try:\n",
        "                icaSignal = np.array(ica.fit_transform(sig))\n",
        "                icaSignal = np.append(icaSignal, sig[:, range(2, 4)], axis=1)\n",
        "                icaRes.append(icaSignal)\n",
        "            except:\n",
        "                pass\n",
        "        return np.array(icaRes)\n",
        "\n",
        "    def createDelayRepetition(self, signal, numberDelay=4, delay=10):\n",
        "        signal = np.repeat(signal, numberDelay, axis=0)\n",
        "        #print(\"createDelayRepetition::\",signal.shape)\n",
        "        for row in range(1, signal.shape[0]):\n",
        "            signal[row, :] = np.roll(signal[row, :], shift=delay * row)\n",
        "\n",
        "        #print(\"createDelayRepetition 2::\",signal.shape)\n",
        "        return signal\n",
        "\n",
        "    def __butter_bandpass(self, lowcut, highcut, fs, order=5):\n",
        "        #print(\"00\")\n",
        "        nyq = 0.5 * fs\n",
        "        #print(\"0\")\n",
        "        low = lowcut / nyq\n",
        "        #print(\"11\")\n",
        "        high = highcut / nyq\n",
        "        b, a = butter(order, [low, high], btype='band')\n",
        "        #print(\"1\")\n",
        "        return b, a\n",
        "\n",
        "    def butter_bandpass_filter(self, data, lowcut, highcut, fs, order=3, axis=1):\n",
        "        #print(\"In butter_bandpass_filter\")\n",
        "        b, a = self.__butter_bandpass(lowcut, highcut, fs, order=order)\n",
        "        y = filtfilt(b, a, data, axis=axis)\n",
        "        #print(\"2\")\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMp0XeQhDxva"
      },
      "outputs": [],
      "source": [
        "'''function for ecg identification, using pan-tompkins algorithm'''\n",
        "\n",
        "def codeFn(ecg, fs):\n",
        "    nyquist = 0.5 * fs\n",
        "    low_cutoff = 5\n",
        "    high_cutoff = 15\n",
        "    b, a = butter(1, [low_cutoff/nyquist, high_cutoff/nyquist], btype='band')\n",
        "    ecg_filt = filtfilt(b, a, ecg)\n",
        "\n",
        "    b = np.array([1, 0, -1])\n",
        "    ecg_diff = np.convolve(ecg_filt, b, mode='same')\n",
        "    ecg_sq = ecg_diff ** 2\n",
        "\n",
        "    ma_len = int(0.08 * fs)\n",
        "    ecg_ma = np.convolve(ecg_sq, np.ones(ma_len)/ma_len, mode='same')\n",
        "\n",
        "    qrs_idx, _ = find_peaks(ecg_ma, distance=int(0.2 * fs), height=0.2 * np.max(ecg_ma))\n",
        "\n",
        "    return qrs_idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cq4SD2XwUbFI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def apply_fft_iifft(data):\n",
        "    \"\"\"\n",
        "    Applies FFT, performs optional frequency-domain operations,\n",
        "    and then reconstructs the data using IFFT.\n",
        "    \"\"\"\n",
        "    # Transform data to the frequency domain\n",
        "    freq_data = np.fft.fft(data)\n",
        "    threshold = len(freq_data) // 2  # Example threshold\n",
        "    freq_data[threshold:] = 0\n",
        "\n",
        "    # Reconstruct data using IFFT\n",
        "    reconstructed_data = np.real(np.fft.ifft(freq_data))\n",
        "\n",
        "    return reconstructed_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyDUBs4I4keJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#from Utils.DataUtils import DataUtils\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "class TrainUtils:\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.dataUtils = DataUtils()\n",
        "\n",
        "    def prepareData(self, delay=5, path=\"/content/drive/MyDrive/drive-download-20230428T081947Z-001/b010.edf\"):\n",
        "        scgAll, ecg, fs = self.dataUtils.readData(0,path)\n",
        "        print(scgAll.shape)\n",
        "        #print(\"scg shape:: \",ecg.shape)\n",
        "        scgAll = scgAll[range(1), :]\n",
        "        #print(\"Number of samples:: \",scg.shape)\n",
        "        delayNum = scgAll.shape[0]\n",
        "        ecgAll = self.dataUtils.createDelayRepetition(ecg, delayNum, delay)\n",
        "        #print(\"scg all shape:: \",ecgAll.shape)\n",
        "        for i in range(1, len(fileNames)):\n",
        "            scg, ecg = self.dataUtils.readData(i,path)\n",
        "            print(\"Number of samples:: \",ecg.shape)\n",
        "            scg = scg[range(1), :]\n",
        "            ecgDelayed = self.dataUtils.createDelayRepetition(ecg, 1, delay)\n",
        "            scgAll = np.append(scgAll, scg, axis=1)\n",
        "            ecgAll = np.append(ecgAll, ecgDelayed, axis=1)\n",
        "        #print(\"SCG all merged shape:: \", scg.shape)\n",
        "        print(\"ECG all merged shape:: \", ecgAll.shape)\n",
        "\n",
        "        original_scg = scgAll\n",
        "        original_ecg = ecgAll\n",
        "        scgWindows, ecgWindows = self.dataUtils.windowingSig(scgAll, ecgAll, windowSize=1000)\n",
        "        # ecgWindows = self.dataUtils.adaptFilterOnSig(scgWindows, ecgWindows)\n",
        "        # scgWindows = self.dataUtils.calculateICA(scgWindows, component=2)\n",
        "        return scgWindows, ecgWindows\n",
        "\n",
        "    def trainTestSplit(self, sig, label, trainPercent, shuffle=True):\n",
        "        print(\"Splitting into train and test:: \")\n",
        "        X_train, X_test, y_train, y_test = train_test_split(sig, label, train_size=trainPercent, shuffle=False)\n",
        "        X_train = np.array(X_train)\n",
        "        #X_train = self.window_the_data(X_train,  60)\n",
        "        X_test = np.array(X_test)\n",
        "        #X_test = self.window_the_data(X_test,  60)\n",
        "        y_train = np.array(y_train)\n",
        "        y_test = np.array(y_test)\n",
        "        return X_train, X_test, y_train, y_test\n",
        "\n",
        "    def window_the_data(self,data,window=32):\n",
        "      r = list()\n",
        "      for i, mat in enumerate(data):\n",
        "        s = 0\n",
        "        a = list()\n",
        "        print(data.shape)\n",
        "        while s + window < 256:\n",
        "          a.append(copy.deepcopy(mat[s : s + window].T))\n",
        "          # for i,x in enumerate(a):\n",
        "            # a[i] = scaler.fit_transform(x)\n",
        "          s += 2\n",
        "        r.append(copy.deepcopy(a))\n",
        "        #print(r.shape())\n",
        "\n",
        "\n",
        "      r = np.array(r)\n",
        "      return copy.deepcopy(r)\n",
        "\n",
        "\n",
        "    def preprocess(self, data):\n",
        "        \"\"\"Apply FFT followed by IFFT preprocessing.\"\"\"\n",
        "        return apply_fft_iifft(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWSGLeDSYotR"
      },
      "source": [
        "    **added 2 discriminators**\n",
        "\n",
        "---\n",
        "\n",
        "* line 103, 104 self.image shape c and d\n",
        "* line 124 - 140 discriminator c and d\n",
        "* line 151, 152 modified generators\n",
        "* line 167, 168 added fake_c and d\n",
        "* line 286 and 287 added batches C and D\n",
        "* line 299-302 added imgs_c, imgs_d\n",
        "* line 310, 311 fake_c and d\n",
        "* line 315, 316 added reconstr_c and d\n",
        "* line 324 added img_c and d for g_loss\n",
        "* line 326-332 added dC and dD loss real and fake\n",
        "* line 335 modified d_loss\n",
        "* line 376-384 added fake_c and d, reconstr_c and d\n",
        "* line 394 added imgs_C, fake_D, reconstr_C, imgs_D, fake_C, reconstr_D to gen_imgs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAw_aBmpNpv0"
      },
      "outputs": [],
      "source": [
        "\n",
        "from __future__ import print_function, division\n",
        "\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv1D, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# from tensorflow_addons.layers import InstanceNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import datetime\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam as legacy_optimizers\n",
        "from tensorflow.keras.layers import LayerNormalization\n",
        "from tensorflow.keras.losses import Huber\n",
        "from tensorflow.keras.layers import LayerNormalization\n",
        "# from dateutil import Dateutils\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "from keras import Input, Model\n",
        "from keras.layers import Conv1D, UpSampling1D, LeakyReLU, Dropout, Lambda, Embedding, Bidirectional, LSTM, Dense, Flatten, Layer, MultiHeadAttention, LayerNormalization, GlobalAveragePooling1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import legacy as legacy_optimizers\n",
        "from keras_contrib.layers import InstanceNormalization\n",
        "# from keras_contrib.layers import BatchNormalization\n",
        "#from keras_self_attention import ScaledDotProductAttention\n",
        "#from keras_self_attention.backend import regularizers\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import Sequential\n",
        "# from tensorflow.python.keras.layers import Normalization\n",
        "from tensorflow.keras.layers import Normalization\n",
        "\n",
        "#from Utils.DataUtils import DataUtils\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv1D, Lambda, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# from tensorflow_addons.layers import InstanceNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import datetime\n",
        "import os\n",
        "!pip install tensorflow-addons\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam as legacy_optimizers\n",
        "from tensorflow.keras.layers import LayerNormalization\n",
        "# from tensorflow.keras.losses import huber_loss\n",
        "from tensorflow.keras.layers import LayerNormalization\n",
        "# from dateutils import Dateutils\n",
        "\n",
        "# class TransformerBlock(Layer):\n",
        "#     def _init_(self, embed_dim, num_heads, rate=0.1):\n",
        "#         super(TransformerBlock, self)._init_()\n",
        "#         self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "#         # self.ffn = Sequential(\n",
        "#         #     [Dense(ff_dim, activation=\"relu\"), Dense(embed_dim), ]\n",
        "#         # )\n",
        "#         #print(\"apply layered normalization\")\n",
        "#         self.layernorm1 = LayerNormalization(epsilon=1e-4)\n",
        "#         # self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "#         #print(\"apply dropout\")\n",
        "#         self.dropout1 = Dropout(rate)\n",
        "#         # self.dropout2 = Dropout(rate)\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         #print(\"In call function of transformer\")\n",
        "#         attn_output = self.att(inputs, inputs)\n",
        "#         attn_output = self.dropout1(attn_output)\n",
        "#         out1 = self.layernorm1(inputs * attn_output)\n",
        "#         # ffn_output = self.ffn(out1)\n",
        "#         # ffn_output = self.dropout2(ffn_output)\n",
        "#         return out1\n",
        "#     def get_config(self):\n",
        "#         \"\"\"\n",
        "#             For rebuilding models on load time.\n",
        "#         \"\"\"\n",
        "\n",
        "#         #config = {\n",
        "#         #    'output_dim': self.output_dim,\n",
        "#         #    'units': self.units,\n",
        "#         #    'return_probabilities': self.return_probabilities\n",
        "#         #}\n",
        "#         base_config = super(TransformerBlock, self).get_config()\n",
        "#         return dict(list(base_config.items()))\n",
        "class TransformerBlock(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, rate=0.01):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        # self.ffn = Sequential(\n",
        "        #     [Dense(ff_dim, activation=\"relu\"), Dense(embed_dim), ]\n",
        "        # )\n",
        "        #print(\"apply layered normalization\")\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-4)\n",
        "        # self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        #print(\"apply dropout\")\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        # self.dropout2 = Dropout(rate)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        #print(\"In call function of transformer\")\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output)\n",
        "        out1 = self.layernorm1(inputs * attn_output)\n",
        "        # ffn_output = self.ffn(out1)\n",
        "        # ffn_output = self.dropout2(ffn_output)\n",
        "        return out1\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "            For rebuilding models on load time.\n",
        "        \"\"\"\n",
        "\n",
        "        #config = {\n",
        "        #    'output_dim': self.output_dim,\n",
        "        #    'units': self.units,\n",
        "        #    'return_probabilities': self.return_probabilities\n",
        "        #}\n",
        "        base_config = super(TransformerBlock, self).get_config()\n",
        "        return dict(list(base_config.items()))\n",
        "\n",
        "\n",
        "\n",
        "def batch_creation(x_train, y_train, batch_size, batch_idx):\n",
        "    batchA = x_train[batch_idx * batch_size: (batch_idx + 1) * batch_size]\n",
        "    batchB = y_train[batch_idx * batch_size: (batch_idx + 1) * batch_size]\n",
        "    return batchA, batchB\n",
        "\n",
        "# @tf.autograph.experimental.do_not_convert\n",
        "class CycleGAN:\n",
        "    def __init__(self, row, col):\n",
        "        gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "        if gpus:\n",
        "            try:\n",
        "                # Restrict TensorFlow to only use the fourth GPU\n",
        "                tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "\n",
        "                # Currently, memory growth needs to be the same across GPUs\n",
        "                for gpu in gpus:\n",
        "                    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "                logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "                print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "            except RuntimeError as e:\n",
        "                # Memory growth must be set before GPUs have been initialized\n",
        "                print(e)\n",
        "        self.dataUtils = DataUtils()\n",
        "        self.img_rows = row\n",
        "        self.img_cols = col\n",
        "        self.channels = 1\n",
        "        self.img_shape = (self.img_rows, self.img_cols)\n",
        "        self.img_shape_b = (self.img_rows, 1)\n",
        "        self.dataset_name = 'ECG2FECG'\n",
        "\n",
        "        # Calculate output shape of D (PatchGAN)\n",
        "        patch = int(self.img_rows / 2 ** 4)\n",
        "        self.disc_patch = (self.img_rows, 1)\n",
        "\n",
        "        # Number of filters in the first layer of G and D\n",
        "        self.gf = 6\n",
        "        self.df = 13\n",
        "\n",
        "        # Loss weights\n",
        "        self.lambda_cycle = 4.0  # Cycle-consistency loss\n",
        "        self.lambda_id = 0.01 * self.lambda_cycle  # Identity loss\n",
        "\n",
        "        # optimizer = Adam()\n",
        "        optimizer = tf.keras.optimizers.legacy.Adam()\n",
        "\n",
        "\n",
        "        # Build and compile the discriminators\n",
        "        self.d_A1 = self.build_discriminator(self.img_shape)\n",
        "        # self.d_A2 = self.build_discriminator(self.img_shape)\n",
        "        self.d_A2 = self.build_discriminator(self.img_shape_b)\n",
        "        self.d_B1 = self.build_discriminator(self.img_shape_b)\n",
        "        self.d_B2 = self.build_discriminator(self.img_shape)\n",
        "        # self.d_B2 = self.build_discriminator(self.img_shape_b)\n",
        "\n",
        "        # Build the generators\n",
        "        self.g_AB = self.build_generator(self.img_shape)\n",
        "        self.g_BA = self.build_generator(self.img_shape_b)\n",
        "\n",
        "        # Compile discriminators\n",
        "        self.d_A1.compile(loss='MSE', optimizer=optimizer, metrics=['accuracy'])\n",
        "        self.d_A2.compile(loss='MSE', optimizer=optimizer, metrics=['accuracy'])\n",
        "        self.d_B1.compile(loss='MSE', optimizer=optimizer, metrics=['accuracy'])\n",
        "        self.d_B2.compile(loss='MSE', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "        # Input images from both domains\n",
        "        img_A = Input(shape=self.img_shape)\n",
        "        img_B = Input(shape=self.img_shape_b)\n",
        "\n",
        "        # Translate images to the other domain\n",
        "        fake_B = self.g_AB(img_A)\n",
        "        fake_A = self.g_BA(img_B)\n",
        "\n",
        "        # Translate images back to original domain\n",
        "        reconstr_A = self.g_BA(fake_B)\n",
        "        reconstr_B = self.g_AB(fake_A)\n",
        "        #print(\"1\")\n",
        "        # Identity mapping of images\n",
        "        img_A_id = self.g_BA(img_A)\n",
        "        img_B_id = self.g_AB(img_B)\n",
        "\n",
        "        #print(\"2\")\n",
        "        # For the combined model we will only train the generators\n",
        "        # self.d_A1.trainable = False\n",
        "        # self.d_A2.trainable = False\n",
        "        # self.d_B1.trainable = False\n",
        "        # self.d_B2.trainable = False\n",
        "        self.d_A1.trainable = True\n",
        "        self.d_A2.trainable = True\n",
        "        self.d_B1.trainable = True\n",
        "        self.d_B2.trainable = True\n",
        "        #print(\"3\")\n",
        "\n",
        "        # Discriminators determine validity of translated images\n",
        "        valid_A1 = self.d_A1(fake_A)\n",
        "        valid_A2 = self.d_A2(fake_A)\n",
        "        valid_B1 = self.d_B1(fake_B)\n",
        "        valid_B2 = self.d_B2(fake_B)\n",
        "\n",
        "        # # Combined model trains generators to fool discriminators\n",
        "        self.combined = Model(inputs=[img_A, img_B],\n",
        "                              outputs=[valid_A1, valid_B1, valid_A2, valid_B2,\n",
        "                                       fake_B, fake_A,\n",
        "                                       reconstr_A, reconstr_B])\n",
        "\n",
        "        # Combined model trains generators to fool discriminators\n",
        "        # self.combined = Model(inputs=[img_A, img_B],\n",
        "        #                       outputs=[valid_A1, valid_A2, valid_B1, valid_B2,\n",
        "        #                                fake_B, fake_A,\n",
        "        #                                reconstr_A, reconstr_B])\n",
        "\n",
        "        # Compile the combined model\n",
        "        self.combined.compile(loss=['huber_loss', 'huber_loss', 'huber_loss', 'huber_loss', 'huber_loss', 'huber_loss', 'huber_loss', 'huber_loss'],\n",
        "                              loss_weights=[1, 1, self.lambda_cycle, self.lambda_cycle, self.lambda_id, self.lambda_id],\n",
        "                              optimizer=optimizer)\n",
        "\n",
        "        # self.combined.compile(loss=[Huber(), Huber(), Huber(), Huber(), Huber(), Huber(), Huber(), Huber()],\n",
        "        #                       loss_weights=[1, 1, self.lambda_cycle, self.lambda_cycle, self.lambda_id, self.lambda_id],\n",
        "        #                       optimizer=optimizer)\n",
        "    # Define custom loss\n",
        "    def custom_loss(self):\n",
        "\n",
        "        # Create a loss function that adds the MSE loss to the mean of all squared activations of a specific layer\n",
        "        def loss(y_true, y_pred):\n",
        "            return K.mean(y_true * K.log(y_true / y_pred + K.epsilon()))\n",
        "\n",
        "        # Return a function\n",
        "        return loss\n",
        "\n",
        "    def build_generator(self,img_shape):\n",
        "        \"\"\"U-Net Generator\"\"\"\n",
        "        print(\"In build generator\")\n",
        "        def conv1DWithSINE(layer_input, filters, f_size=60):\n",
        "            \"\"\"Layers used during downsampling\"\"\"\n",
        "            # d = Conv1D(filters, kernel_size=f_size, padding='same', activation='sigmoid')(layer_input)\n",
        "            d = Conv1D(filters, kernel_size=f_size, padding='same', activation='LeakyReLU')(layer_input)\n",
        "            d = InstanceNormalization()(d)\n",
        "            d = InstanceNormalization()(d)\n",
        "            d = BatchNormalization()(d)\n",
        "            return d\n",
        "\n",
        "        def multiply(x):\n",
        "            mask,image  = x\n",
        "            return image* K.clip(mask,0.8,1)\n",
        "\n",
        "        input = Input(shape=img_shape)\n",
        "        print(\"Input shape:: \", input.shape)\n",
        "        # value = conv1DWithSINE(input, input.shape[2], f_size=30)\n",
        "        value = conv1DWithSINE(input, 30, f_size=60)\n",
        "        print(\" shape after conv1d :: \", value.shape)\n",
        "\n",
        "        print(\"apply attention.\")\n",
        "        att = TransformerBlock(embed_dim=input.shape[1], num_heads=2)(value)\n",
        "        print(\"shape after attention:: \",att.shape )\n",
        "        att = Normalization(axis=1)(att)\n",
        "        print(\"shape after normalizing attention:: \",att.shape )\n",
        "\n",
        "        remainedInput = Lambda(multiply)([att, value])\n",
        "        print(\"shape after apply lambda:: \",remainedInput.shape )\n",
        "\n",
        "        output_img = conv1DWithSINE(remainedInput, 17, f_size=240)#60\n",
        "        output_img = conv1DWithSINE(output_img, 13, f_size=240)#60\n",
        "        output_img = conv1DWithSINE(output_img, 13, f_size=240)#60\n",
        "        output_img = conv1DWithSINE(output_img, 1, f_size=1)\n",
        "\n",
        "        return Model(input, output_img)\n",
        "\n",
        "    def build_discriminator(self,img_shape):\n",
        "        print(\"In building discriminator\")\n",
        "        def d_layer(layer_input, filters, f_size=33, normalization=True):\n",
        "            \"\"\"Discriminator layer\"\"\"\n",
        "            # d = Conv1D(filters, kernel_size=f_size, padding='same',activation='sigmoid')(layer_input)\n",
        "            d = Conv1D(filters, kernel_size=f_size, padding='same',activation='LeakyReLU')(layer_input)\n",
        "            if normalization:\n",
        "                d = InstanceNormalization()(d)\n",
        "                d = BatchNormalization()(d)\n",
        "            return d\n",
        "\n",
        "        img = Input(shape=img_shape)\n",
        "        print(\"input shape:: \",img.shape)\n",
        "        d1 = d_layer(img, self.df)\n",
        "        print(\"input shape after first conv1d:: \",d1.shape)\n",
        "        d2 = d_layer(d1, 13)\n",
        "        print(\"input shape after second conv1d:: \",d2.shape)\n",
        "        d3 = d_layer(d2, 13)\n",
        "        print(\"input shape after third conv1d:: \",d3.shape)\n",
        "        d4 = d_layer(d3, 13)\n",
        "        print(\"input shape after fourth conv1d:: \",d3.shape)\n",
        "        d5 = d_layer(d4, 13)\n",
        "        print(\"input shape after fifth conv1d:: \",d3.shape)\n",
        "        d6 = d_layer(d5, 13)\n",
        "        print(\"input shape after sixth conv1d:: \",d3.shape)\n",
        "        validity = d_layer(d6, 1)\n",
        "        # validity = d_layer(d3, img.shape[1])\n",
        "        print(\"final shape after 6th layer:: \",validity.shape)\n",
        "\n",
        "\n",
        "        return Model(img, validity)\n",
        "\n",
        "    def train(self, x_train, y_train, epochs, batch_size=1, sample_interval=5):\n",
        "        print(\"Num Samples\", x_train.shape[0])\n",
        "        print(\"In train:: \")\n",
        "        start_time = datetime.datetime.now()\n",
        "\n",
        "        # Adversarial loss ground truths\n",
        "        valid = np.ones((batch_size,) + self.disc_patch)\n",
        "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            for batch_idx in range(x_train.shape[0] // batch_size):\n",
        "                batchA, batchB = batch_creation(x_train, y_train, batch_size, batch_idx)\n",
        "                batchA = np.asarray(batchA)\n",
        "                batchB = np.asarray(batchB)\n",
        "\n",
        "                imgs_A = batchA\n",
        "                imgs_B = batchB\n",
        "\n",
        "                imgs_B = np.reshape(imgs_B, (-1, x_train.shape[1], x_train.shape[2]))\n",
        "                imgs_A = np.reshape(imgs_A, (-1, x_train.shape[1], x_train.shape[2]))\n",
        "\n",
        "                # ----------------------\n",
        "                #  Train Discriminators\n",
        "                # ----------------------\n",
        "\n",
        "                # Translate images to the other domain\n",
        "                fake_B = self.g_AB.predict(imgs_A)\n",
        "                fake_A = self.g_BA.predict(imgs_B)\n",
        "                # fake_D = self.g_AB.predict(imgs_C)\n",
        "                # fake_C = self.g_BA.predict(imgs_D)\n",
        "\n",
        "                # Translate images back to original domain\n",
        "                reconstr_A = self.g_BA.predict(fake_B)\n",
        "                reconstr_B = self.g_AB.predict(fake_A)\n",
        "                # reconstr_C = self.g_BA.predict(fake_D)\n",
        "                # reconstr_D = self.g_AB.predict(fake_C)\n",
        "\n",
        "                # Train the discriminators (original images = real / translated = Fake)\n",
        "                dA_loss_real = self.d_A1.train_on_batch(imgs_A, valid)\n",
        "                dA_loss_fake = self.d_A1.train_on_batch(fake_A, fake)\n",
        "                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
        "\n",
        "                dB_loss_real = self.d_B1.train_on_batch(imgs_B, valid)#b\n",
        "                dB_loss_fake = self.d_B1.train_on_batch(fake_B, fake)\n",
        "                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
        "\n",
        "                dC_loss_real = self.d_A2.train_on_batch(imgs_B, valid)#a\n",
        "                dC_loss_fake = self.d_A2.train_on_batch(fake_B, fake)\n",
        "                dC_loss = 0.5 * np.add(dC_loss_real, dC_loss_fake)\n",
        "\n",
        "                dD_loss_real = self.d_B2.train_on_batch(imgs_A, valid)#a\n",
        "                dD_loss_fake = self.d_B2.train_on_batch(fake_A, fake)\n",
        "                dD_loss = 0.5 * np.add(dD_loss_real, dD_loss_fake)\n",
        "\n",
        "                # Total discriminator loss\n",
        "                # d_loss = 0.25 * (dA_loss + dB_loss + dC_loss + dD_loss)\n",
        "                # Total discriminator loss\n",
        "                d_loss = 0.25 * (np.add(np.add(dA_loss, dB_loss), np.add(dC_loss, dD_loss)))\n",
        "\n",
        "                # d_loss = 0.25 * np.add(dA_loss, dB_loss, dC_loss, dD_loss)\n",
        "\n",
        "                # Discriminators determine validity of translated images\n",
        "                # valid_A1 = self.d_A1(fake_A)\n",
        "                # valid_A2 = self.d_A2(fake_A)\n",
        "                # valid_B1 = self.d_B1(fake_B)\n",
        "                # valid_B2 = self.d_B2(fake_B)\n",
        "\n",
        "                # # Combined model trains generators to fool discriminators\n",
        "                # self.combined.compile(loss=[Huber(), Huber(), Huber(), Huber(), Huber(), Huber()],\n",
        "                #                       loss_weights=[1, 1, self.lambda_cycle, self.lambda_cycle, self.lambda_id, self.lambda_id],\n",
        "                #                       optimizer=tf.keras.optimizers.legacy.Adam())\n",
        "\n",
        "                g_loss = self.combined.train_on_batch([imgs_A, imgs_B],\n",
        "                                                      [valid, valid, valid, valid,\n",
        "                                                       imgs_B, imgs_A,\n",
        "                                                       reconstr_A, reconstr_B])\n",
        "\n",
        "\n",
        "                # ------------------\n",
        "                #  Train Generators\n",
        "                # ------------------\n",
        "\n",
        "                # Train the generators\n",
        "\n",
        "                # g_loss = self.combined.train_on_batch([imgs_A, imgs_B, imgs_C, imgs_D],\n",
        "                #                                       [valid, valid, valid, valid,\n",
        "                #                                        imgs_B, imgs_A, imgs_D, imgs_C,\n",
        "                #                                        reconstr_A, reconstr_B,\n",
        "                #                                        reconstr_C, reconstr_D])\n",
        "                # g_loss = self.combined.train_on_batch([imgs_A, imgs_B],\n",
        "                #                                       [valid, valid,\n",
        "                #                                        imgs_B, imgs_A,\n",
        "                #                                        reconstr_A, reconstr_B])\n",
        "                # g_loss = self.combined.train_on_batch([imgs_A, imgs_B, imgs_C, imgs_D],\n",
        "                #                       [valid, valid, valid, valid,\n",
        "                #                        imgs_B, imgs_A, imgs_D, imgs_C,\n",
        "                #                        reconstr_A, reconstr_B,\n",
        "                #                        reconstr_C, reconstr_D])\n",
        "\n",
        "\n",
        "                # # Translate images to the other domain\n",
        "                # fake_B = self.g_AB.predict(imgs_A)\n",
        "                # fake_A = self.g_BA.predict(imgs_B)\n",
        "                # # Translate images back to original domain\n",
        "                # reconstr_A = self.g_BA.predict(fake_B)\n",
        "                # reconstr_B = self.g_AB.predict(fake_A)\n",
        "                # # Train the discriminators (original images = real / translated = Fake)\n",
        "                # dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n",
        "                # dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n",
        "                # dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
        "\n",
        "                # dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n",
        "                # dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n",
        "                # dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
        "\n",
        "                # # Total disciminator loss\n",
        "                # d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
        "\n",
        "                # # ------------------\n",
        "                # #  Train Generators\n",
        "                # # ------------------\n",
        "\n",
        "\n",
        "                # # Train the generators\n",
        "                # g_loss = self.combined.train_on_batch([imgs_A, imgs_B, imgs_C, imgs_D],\n",
        "                #                                       [valid, valid,\n",
        "                #                                        imgs_B, imgs_A,\n",
        "                #                                        reconstr_A, reconstr_B,\n",
        "                #                                        valid_C, valid_D])\n",
        "\n",
        "                elapsed_time = datetime.datetime.now() - start_time\n",
        "\n",
        "                # Plot the progress\n",
        "                print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \" \\\n",
        "                      % (epoch, epochs,\n",
        "                         batch_idx, 1,\n",
        "                         d_loss[0], 100 * d_loss[1],\n",
        "                         g_loss[0],\n",
        "                         np.mean(g_loss[1:3]),\n",
        "                         np.mean(g_loss[3:5]),\n",
        "                         np.mean(g_loss[5:6]),\n",
        "                         elapsed_time))\n",
        "\n",
        "                # If at save interval => save generated image samples\n",
        "                #print(\"shape of image a\",imgs_A.shape)\n",
        "                #print(\"shape of image b\",imgs_B.shape)\n",
        "                if batch_idx % sample_interval == 0:\n",
        "                    self.sample_images(epoch, batch_idx, imgs_A, imgs_B)\n",
        "                    self.g_AB.save(\"ECG2FECG.h5\", overwrite=True)\n",
        "                    self.g_BA.save(\"FECG2ECG.h5\", overwrite=True)\n",
        "\n",
        "    def sample_images(self, epoch, batch_idx, imgs_A, imgs_B):\n",
        "        os.makedirs('images/%s' % self.dataset_name, exist_ok=True)\n",
        "        r, c = 2, 3\n",
        "\n",
        "        # Demo (for GIF)\n",
        "        # imgs_A = self.data_loader.load_img('datasets/apple2orange/testA/n07740461_1541.jpg')\n",
        "        # imgs_B = self.data_loader.load_img('datasets/apple2orange/testB/n07749192_4241.jpg')\n",
        "\n",
        "        # Translate images to the other domain\n",
        "        fake_B = self.g_AB.predict(imgs_A)\n",
        "        fake_A = self.g_BA.predict(imgs_B)\n",
        "        # fake_D = self.g_AB.predict(imgs_B)\n",
        "        # fake_C = self.g_BA.predict(imgs_A)\n",
        "        # Translate back to original domain\n",
        "        reconstr_A = self.g_BA.predict(fake_B)\n",
        "        reconstr_B = self.g_AB.predict(fake_A)\n",
        "        # reconstr_C = self.g_BA.predict(fake_D)\n",
        "        # reconstr_D = self.g_AB.predict(fake_C)\n",
        "\n",
        "\n",
        "        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n",
        "        #print(\"shape of gen\",gen_imgs.shape)\n",
        "        # Rescale images 0 - 1\n",
        "        # gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        titles = ['Original', 'Translated', 'Reconstructed']\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "\n",
        "        # gen_imgs[1] = gen_imgs[0]-gen_imgs[1]\n",
        "        try:\n",
        "            for i in range(r):\n",
        "                for j in range(c):\n",
        "                    for bias in range(1):\n",
        "                        #gen_imgs[cnt][:, bias] = scale(self.dataUtils.butter_bandpass_filter(gen_imgs[cnt][:, bias], 10, 50, 200, axis=0), axis=0)\n",
        "                        #gen_imgs[cnt][:, bias] = scale(gen_imgs[cnt][:, bias], axis=0)\n",
        "                        if np.max(gen_imgs[cnt][:, bias]) != 0:\n",
        "                            gen_imgs[cnt][:, bias] = gen_imgs[cnt][:, bias] / np.max(gen_imgs[cnt][:, bias])\n",
        "                        axs[i, j].plot(gen_imgs[cnt][:, bias] + bias)\n",
        "                    axs[i, j].set_title(titles[j])\n",
        "                    cnt += 1\n",
        "            # fig.savefig(\"images/%s/%d_%d.png\" % (self.dataset_name, epoch, batch_idx))\n",
        "            plt.close()\n",
        "        except:\n",
        "            pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWEa6jqtQECU"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "from keras import regularizers, constraints, initializers, activations\n",
        "from keras.layers import TimeDistributed\n",
        "#from keras.layers.recurrent import Recurrent\n",
        "from tensorflow.keras.layers import InputSpec\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class AttentionDecoder():\n",
        "\n",
        "    def __init__(self, units, output_dim,\n",
        "                 activation='tanh',\n",
        "                 return_probabilities=False,\n",
        "                 name='AttentionDecoder',\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 recurrent_initializer='orthogonal',\n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_regularizer=None,\n",
        "                 bias_regularizer=None,\n",
        "                 activity_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 bias_constraint=None,\n",
        "                 **kwargs):\n",
        "        \"\"\"\n",
        "        Implements an AttentionDecoder that takes in a sequence encoded by an\n",
        "        encoder and outputs the decoded states\n",
        "        :param units: dimension of the hidden state and the attention matrices\n",
        "        :param output_dim: the number of labels in the output space\n",
        "        references:\n",
        "            Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio.\n",
        "            \"Neural machine translation by jointly learning to align and translate.\"\n",
        "            arXiv preprint arXiv:1409.0473 (2014).\n",
        "        \"\"\"\n",
        "        self.units = units\n",
        "        self.output_dim = output_dim\n",
        "        self.return_probabilities = return_probabilities\n",
        "        self.activation = activations.get(activation)\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.recurrent_initializer = initializers.get(recurrent_initializer)\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.recurrent_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
        "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "\n",
        "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
        "        self.recurrent_constraint = constraints.get(kernel_constraint)\n",
        "        self.bias_constraint = constraints.get(bias_constraint)\n",
        "\n",
        "        super(AttentionDecoder, self).__init__(**kwargs)\n",
        "        self.name = name\n",
        "        self.return_sequences = True  # must return sequences\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"\n",
        "          See Appendix 2 of Bahdanau 2014, arXiv:1409.0473\n",
        "          for model details that correspond to the matrices here.\n",
        "        \"\"\"\n",
        "\n",
        "        self.batch_size, self.timesteps, self.input_dim = input_shape\n",
        "\n",
        "        if self.stateful:\n",
        "            super(AttentionDecoder, self).reset_states()\n",
        "\n",
        "        self.states = [None, None]  # y, s\n",
        "\n",
        "        \"\"\"\n",
        "            Matrices for creating the context vector\n",
        "        \"\"\"\n",
        "\n",
        "        self.V_a = self.add_weight(shape=(self.units,),\n",
        "                                   name='V_a',\n",
        "                                   initializer=self.kernel_initializer,\n",
        "                                   regularizer=self.kernel_regularizer,\n",
        "                                   constraint=self.kernel_constraint)\n",
        "        self.W_a = self.add_weight(shape=(self.units, self.units),\n",
        "                                   name='W_a',\n",
        "                                   initializer=self.kernel_initializer,\n",
        "                                   regularizer=self.kernel_regularizer,\n",
        "                                   constraint=self.kernel_constraint)\n",
        "        self.U_a = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                   name='U_a',\n",
        "                                   initializer=self.kernel_initializer,\n",
        "                                   regularizer=self.kernel_regularizer,\n",
        "                                   constraint=self.kernel_constraint)\n",
        "        self.b_a = self.add_weight(shape=(self.units,),\n",
        "                                   name='b_a',\n",
        "                                   initializer=self.bias_initializer,\n",
        "                                   regularizer=self.bias_regularizer,\n",
        "                                   constraint=self.bias_constraint)\n",
        "        \"\"\"\n",
        "            Matrices for the r (reset) gate\n",
        "        \"\"\"\n",
        "        self.C_r = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                   name='C_r',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.U_r = self.add_weight(shape=(self.units, self.units),\n",
        "                                   name='U_r',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.W_r = self.add_weight(shape=(self.output_dim, self.units),\n",
        "                                   name='W_r',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.b_r = self.add_weight(shape=(self.units,),\n",
        "                                   name='b_r',\n",
        "                                   initializer=self.bias_initializer,\n",
        "                                   regularizer=self.bias_regularizer,\n",
        "                                   constraint=self.bias_constraint)\n",
        "\n",
        "        \"\"\"\n",
        "            Matrices for the z (update) gate\n",
        "        \"\"\"\n",
        "        self.C_z = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                   name='C_z',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.U_z = self.add_weight(shape=(self.units, self.units),\n",
        "                                   name='U_z',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.W_z = self.add_weight(shape=(self.output_dim, self.units),\n",
        "                                   name='W_z',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.b_z = self.add_weight(shape=(self.units,),\n",
        "                                   name='b_z',\n",
        "                                   initializer=self.bias_initializer,\n",
        "                                   regularizer=self.bias_regularizer,\n",
        "                                   constraint=self.bias_constraint)\n",
        "        \"\"\"\n",
        "            Matrices for the proposal\n",
        "        \"\"\"\n",
        "        self.C_p = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                   name='C_p',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.U_p = self.add_weight(shape=(self.units, self.units),\n",
        "                                   name='U_p',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.W_p = self.add_weight(shape=(self.output_dim, self.units),\n",
        "                                   name='W_p',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.b_p = self.add_weight(shape=(self.units,),\n",
        "                                   name='b_p',\n",
        "                                   initializer=self.bias_initializer,\n",
        "                                   regularizer=self.bias_regularizer,\n",
        "                                   constraint=self.bias_constraint)\n",
        "        \"\"\"\n",
        "            Matrices for making the final prediction vector\n",
        "        \"\"\"\n",
        "        self.C_o = self.add_weight(shape=(self.input_dim, self.output_dim),\n",
        "                                   name='C_o',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.U_o = self.add_weight(shape=(self.units, self.output_dim),\n",
        "                                   name='U_o',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.W_o = self.add_weight(shape=(self.output_dim, self.output_dim),\n",
        "                                   name='W_o',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.b_o = self.add_weight(shape=(self.output_dim,),\n",
        "                                   name='b_o',\n",
        "                                   initializer=self.bias_initializer,\n",
        "                                   regularizer=self.bias_regularizer,\n",
        "                                   constraint=self.bias_constraint)\n",
        "\n",
        "        # For creating the initial state:\n",
        "        self.W_s = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                   name='W_s',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "\n",
        "        self.input_spec = [\n",
        "            InputSpec(shape=(self.batch_size, self.timesteps, self.input_dim))]\n",
        "        self.built = True\n",
        "\n",
        "    def _time_distributed_dense(self,x, w, b=None, dropout=None,\n",
        "                                input_dim=None, output_dim=None,\n",
        "                                timesteps=None, training=None):\n",
        "        \"\"\"Apply `y . w + b` for every temporal slice y of x.\n",
        "        # Arguments\n",
        "            x: input tensor.\n",
        "            w: weight matrix.\n",
        "            b: optional bias vector.\n",
        "            dropout: wether to apply dropout (same dropout mask\n",
        "                for every temporal slice of the input).\n",
        "            input_dim: integer; optional dimensionality of the input.\n",
        "            output_dim: integer; optional dimensionality of the output.\n",
        "            timesteps: integer; optional number of timesteps.\n",
        "            training: training phase tensor or boolean.\n",
        "        # Returns\n",
        "            Output tensor.\n",
        "        \"\"\"\n",
        "        if not input_dim:\n",
        "            input_dim = K.shape(x)[2]\n",
        "        if not timesteps:\n",
        "            timesteps = K.shape(x)[1]\n",
        "        if not output_dim:\n",
        "            output_dim = K.shape(w)[1]\n",
        "\n",
        "        if dropout is not None and 0. < dropout < 1.:\n",
        "            # apply the same dropout pattern at every timestep\n",
        "            ones = K.ones_like(K.reshape(x[:, 0, :], (-1, input_dim)))\n",
        "            dropout_matrix = K.dropout(ones, dropout)\n",
        "            expanded_dropout_matrix = K.repeat(dropout_matrix, timesteps)\n",
        "            x = K.in_train_phase(x * expanded_dropout_matrix, x, training=training)\n",
        "\n",
        "        # collapse time dimension and batch dimension together\n",
        "        x = K.reshape(x, (-1, input_dim))\n",
        "        x = K.dot(x, w)\n",
        "        if b is not None:\n",
        "            x = K.bias_add(x, b)\n",
        "        # reshape to 3D tensor\n",
        "        if K.backend() == 'tensorflow':\n",
        "            x = K.reshape(x, K.stack([-1, timesteps, output_dim]))\n",
        "            x.set_shape([None, None, output_dim])\n",
        "        else:\n",
        "            x = K.reshape(x, (-1, timesteps, output_dim))\n",
        "        return x\n",
        "\n",
        "    def call(self, x):\n",
        "        # store the whole sequence so we can \"attend\" to it at each timestep\n",
        "        self.x_seq = x\n",
        "\n",
        "        # apply the a dense layer over the time dimension of the sequence\n",
        "        # do it here because it doesn't depend on any previous steps\n",
        "        # thefore we can save computation time:\n",
        "        self._uxpb = self._time_distributed_dense(self.x_seq, self.U_a, b=self.b_a,\n",
        "                                             input_dim=self.input_dim,\n",
        "                                             timesteps=self.timesteps,\n",
        "                                             output_dim=self.units)\n",
        "\n",
        "        return super(AttentionDecoder, self).call(x, )\n",
        "\n",
        "    def get_initial_state(self, inputs):\n",
        "        # apply the matrix on the first time step to get the initial s0.\n",
        "        s0 = activations.tanh(K.dot(inputs[:, 0], self.W_s))\n",
        "\n",
        "        # from keras.layers.recurrent to initialize a vector of (batchsize,\n",
        "        # output_dim)\n",
        "        y0 = K.zeros_like(inputs)  # (samples, timesteps, input_dims)\n",
        "        y0 = K.sum(y0, axis=(1, 2))  # (samples, )\n",
        "        y0 = K.expand_dims(y0)  # (samples, 1)\n",
        "        y0 = K.tile(y0, [1, self.output_dim])\n",
        "\n",
        "        return [y0, s0]\n",
        "\n",
        "    def step(self, x, states):\n",
        "\n",
        "        ytm, stm = states\n",
        "\n",
        "        # repeat the hidden state to the length of the sequence\n",
        "        _stm = K.repeat(stm, self.timesteps)\n",
        "\n",
        "        # now multiplty the weight matrix with the repeated hidden state\n",
        "        _Wxstm = K.dot(_stm, self.W_a)\n",
        "\n",
        "        # calculate the attention probabilities\n",
        "        # this relates how much other timesteps contributed to this one.\n",
        "        et = K.dot(activations.tanh(_Wxstm + self._uxpb),\n",
        "                   K.expand_dims(self.V_a))\n",
        "        at = K.exp(et)\n",
        "        at_sum = K.sum(at, axis=1)\n",
        "        at_sum_repeated = K.repeat(at_sum, self.timesteps)\n",
        "        at /= at_sum_repeated  # vector of size (batchsize, timesteps, 1)\n",
        "\n",
        "        # calculate the context vector\n",
        "        context = K.squeeze(K.batch_dot(at, self.x_seq, axes=1), axis=1)\n",
        "        # ~~~> calculate new hidden state\n",
        "        # first calculate the \"r\" gate:\n",
        "\n",
        "        rt = activations.sigmoid(\n",
        "            K.dot(ytm, self.W_r)\n",
        "            + K.dot(stm, self.U_r)\n",
        "            + K.dot(context, self.C_r)\n",
        "            + self.b_r)\n",
        "\n",
        "        # now calculate the \"z\" gate\n",
        "        zt = activations.sigmoid(\n",
        "            K.dot(ytm, self.W_z)\n",
        "            + K.dot(stm, self.U_z)\n",
        "            + K.dot(context, self.C_z)\n",
        "            + self.b_z)\n",
        "\n",
        "        # calculate the proposal hidden state:\n",
        "        s_tp = activations.tanh(\n",
        "            K.dot(ytm, self.W_p)\n",
        "            + K.dot((rt * stm), self.U_p)\n",
        "            + K.dot(context, self.C_p)\n",
        "            + self.b_p)\n",
        "\n",
        "        # new hidden state:\n",
        "        st = (1 - zt) * stm + zt * s_tp\n",
        "\n",
        "        yt = activations.softmax(\n",
        "            K.dot(ytm, self.W_o)\n",
        "            + K.dot(stm, self.U_o)\n",
        "            + K.dot(context, self.C_o)\n",
        "            + self.b_o)\n",
        "\n",
        "        if self.return_probabilities:\n",
        "            return at, [yt, st]\n",
        "        else:\n",
        "            return yt, [yt, st]\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\"\n",
        "            For Keras internal compatability checking\n",
        "        \"\"\"\n",
        "        if self.return_probabilities:\n",
        "            return (None, self.timesteps, self.timesteps)\n",
        "        else:\n",
        "            return (None, self.timesteps, self.output_dim)\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "            For rebuilding models on load time.\n",
        "        \"\"\"\n",
        "        config = {\n",
        "            'output_dim': self.output_dim,\n",
        "            'units': self.units,\n",
        "            'return_probabilities': self.return_probabilities\n",
        "        }\n",
        "        base_config = super(AttentionDecoder, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-bnbz6NG6rq"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "\n",
        "\n",
        "# # See https://github.com/keras-rl/keras-rl/blob/master/rl/memory.py\n",
        "# def zeros_like(a, dtype='float32'):\n",
        "#     \"\"\"Return an array of zeros with same shape as given array.\n",
        "\n",
        "#     Args:\n",
        "#         a (array_like, iterable): An object with shape attribute or an iterable.\n",
        "\n",
        "#     Returns:\n",
        "#         (array_like, list): Array of zeros with the same shape as a.\n",
        "#     \"\"\"\n",
        "#     if hasattr(a, 'shape'):\n",
        "#         if hasattr(a, 'dtype'):\n",
        "#             dtype = a.dtype\n",
        "#         return np.zeros(a.shape, dtype=dtype)\n",
        "#     if hasattr(a, '__iter__'):\n",
        "#         return [zeros_like(b, dtype=dtype) for b in a]\n",
        "#     return 0.\n",
        "\n",
        "\n",
        "\n",
        "# def check_shape(a, b):\n",
        "#     \"\"\"Check if the shapes of given values match.\n",
        "\n",
        "#     Args:\n",
        "#         a (array_like, tuple): An object with shape attribute or a tuple representing shape.\n",
        "#         b (array_like, tuple): An object with shape attribute or a tuple representing shape.\n",
        "\n",
        "#     Raises:\n",
        "#         Exception: When shapes don't match.\n",
        "#     \"\"\"\n",
        "#     if hasattr(a, 'shape'):\n",
        "#         a = a.shape\n",
        "#     if hasattr(b, 'shape'):\n",
        "#         b = b.shape\n",
        "#     assert a == b, f\"Shapes {a} and {b} don't match\"\n",
        "\n",
        "\n",
        "\n",
        "# def unique(a):\n",
        "#     res = {id(v): v for v in a}\n",
        "#     return list(res.values())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXdJaaSpNkfO"
      },
      "outputs": [],
      "source": [
        "\n",
        "from unittest import TestCase\n",
        "import numpy as np\n",
        "\n",
        "# from utils.TrainUtils import TrainUtil\n",
        "# from utils.TrainUtils import TrainUtils\n",
        "# from deeplearning.CycleGAN import CycleGAN\n",
        "\n",
        "\n",
        "class TestCycleGAN(TestCase):\n",
        "\n",
        "    def __init__(self, methodName: str = ...) -> None:\n",
        "        super().__init__(methodName)\n",
        "        self.trainUtils = TrainUtils()\n",
        "\n",
        "    def test_trainSignal(self,path=\"/content/drive/MyDrive/drive-download-20230428T081947Z-001/b009.edf\"):\n",
        "        scgWindows, ecgWindows = self.trainUtils.prepareData(delay=2,path=\"/content/drive/MyDrive/drive-download-20230428T081947Z-001/\")\n",
        "        print(\"ecgWindows:: \",np.array(ecgWindows).shape)\n",
        "        X_train, X_test, Y_train, y_test = self.trainUtils.trainTestSplit(scgWindows, ecgWindows, 0.75)\n",
        "        X_train = np.reshape(X_train, [-1, X_train.shape[1], X_train.shape[2]])\n",
        "        # X_test = np.reshape(X_test, [-1, X_test.shape[1], X_test.shape[2], 1])\n",
        "        Y_train = np.reshape(Y_train, [-1, Y_train.shape[1], Y_train.shape[2]])\n",
        "\n",
        "        print(\"Shape of x train and y train:: \",X_train.shape, Y_train.shape)\n",
        "        print(\"Shape of x test and y test:: \",X_test.shape, y_test.shape)\n",
        "        # y_test = np.reshape(Y_test, [-1, Y_test.shape[1], Y_test.shape[2], 1])\n",
        "        cycleGAN = CycleGAN(X_train.shape[1], X_train.shape[2])\n",
        "        print(\"model instantiated\")\n",
        "        cycleGAN.train(x_train=X_train, y_train=Y_train, epochs=1)\n",
        "        return cycleGAN, X_test, y_test\n",
        "\n",
        "\n",
        "    def divide_test_train(self,path=\"/content/drive/MyDrive/drive-download-20230428T081947Z-001/b009.edf\"):\n",
        "        scgWindows, ecgWindows = self.trainUtils.prepareData(delay=2,path=\"/content/drive/MyDrive/drive-download-20230428T081947Z-001\")\n",
        "        X_train, X_test, Y_train, y_test = self.trainUtils.trainTestSplit(scgWindows, ecgWindows, 0.75)\n",
        "        return X_train, X_test, Y_train, y_test\n",
        "\n",
        "    def preprocess(self, data):\n",
        "        \"\"\"Apply FFT followed by IFFT preprocessing.\"\"\"\n",
        "        return apply_fft_iifft(data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOqLtJow4Sbk"
      },
      "outputs": [],
      "source": [
        "model = TestCycleGAN(\"test_trainSignal\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Nk72Kbz7AxB"
      },
      "outputs": [],
      "source": [
        "# @tf.autograph.experimental.do_not_convert\n",
        "cycleGan, X_test, y_test = model.test_trainSignal()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pg9qXAupK8yP"
      },
      "outputs": [],
      "source": [
        "#model = TestcycleGAN(\"test_trainSignal\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6if5-W4ALCFs"
      },
      "outputs": [],
      "source": [
        "#cycleGan, X_test, y_test = model.test_trainSignal()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_EyygfkiS9D"
      },
      "outputs": [],
      "source": [
        "x_g_AB =cycleGan.g_AB.predict(X_test)\n",
        "#x_g_BA = cycleGan.g_BA.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOoeJ1miu81V"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# a = np.array(y_test.flatten())\n",
        "# b = x_g_AB.flatten()\n",
        "# print(len(a), len(b))\n",
        "# df1 = pd.DataFrame({ \"ECG Original\" : a})\n",
        "# df2 = pd.DataFrame({ \"ECG Predicted\" : b})\n",
        "# df1.to_csv(\"/content/drive/MyDrive/ECG_data/original_ECG_1.csv\", index=False)\n",
        "# df2.to_csv(\"/content/drive/MyDrive/ECG_data/generated_ECG_1.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# a = np.array(original_scg)\n",
        "a = np.array(y_test.flatten())\n",
        "b = x_g_AB.flatten()\n",
        "print(len(a), len(b))\n",
        "df1 = pd.DataFrame({ \"ECG Original\" : a})\n",
        "df2 = pd.DataFrame({ \"ECG Predicted\" : b})\n",
        "df1.to_csv(\"original_ECG_10.csv\", index=False)\n",
        "#df2.to_csv(\"/content/drive/MyDrive/ECG_data/generated_ECG_10.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcUbWMkcVTQA"
      },
      "outputs": [],
      "source": [
        "#!pip install heartpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpOjSUASVWzH"
      },
      "outputs": [],
      "source": [
        "import heartpy as hp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sample_rate = 250"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ld_q3I2VaDl"
      },
      "outputs": [],
      "source": [
        "data = hp.get_data('/content/original_ECG_10.csv')\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(data)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwCoAPRaVgN7"
      },
      "outputs": [],
      "source": [
        "#run analysis\n",
        "wd, m = hp.process(data[1:], sample_rate)\n",
        "\n",
        "#visualise in plot of custom size\n",
        "plt.figure(figsize=(12,4))\n",
        "hp.plotter(wd, m)\n",
        "#print(len(wd['hr']))\n",
        "#print(wd.keys())\n",
        "#print(wd['RR_list'])\n",
        "#heart rates\n",
        "hrs = 60000/wd['RR_list']\n",
        "print(\"heart rates: \",hrs)\n",
        "#display computed measures\n",
        "for measure in m.keys():\n",
        "    print('%s: %f' %(measure, m[measure]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRmQp2UPVjL0"
      },
      "outputs": [],
      "source": [
        "\n",
        "df2 = pd.DataFrame({ \"Heart Rate\" : np.array(hrs)})\n",
        "df2.to_csv(\"hr_original_10.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMobxa04W9_2"
      },
      "outputs": [],
      "source": [
        "# data = hp.get_data('original_ECG_15.csv')\n",
        "\n",
        "# plt.figure(figsize=(12,4))\n",
        "# plt.plot(data)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1qofWbnXE6x"
      },
      "outputs": [],
      "source": [
        "#run analysis\n",
        "wd, m = hp.process(data[1:], sample_rate)\n",
        "\n",
        "#visualise in plot of custom size\n",
        "plt.figure(figsize=(12,4))\n",
        "hp.plotter(wd, m)\n",
        "#print(len(wd['hr']))\n",
        "#print(wd.keys())\n",
        "#print(wd['RR_list'])\n",
        "#heart rates\n",
        "hrs = 60000/wd['RR_list']\n",
        "print(\"heart rates: \",hrs)\n",
        "#display computed measures\n",
        "for measure in m.keys():\n",
        "    print('%s: %f' %(measure, m[measure]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGAOERatXImS"
      },
      "outputs": [],
      "source": [
        "\n",
        "# df2 = pd.DataFrame({ \"Heart Rate\" : np.array(hrs)})\n",
        "# df2.to_csv(\"/content/drive/MyDrive/ECG_data/hr_original_12.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9FkK6KzUdUK"
      },
      "outputs": [],
      "source": [
        "# data = hp.get_data('/content/drive/MyDrive/ECG_data/hr_original_10.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Md_oDmlrAEfa"
      },
      "outputs": [],
      "source": [
        "for i in range(len(data)):\n",
        "  if data[i]>500:\n",
        "    data[i]=data[i]/10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8h-0_RjqAHTX"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# df2 = pd.DataFrame({ \"Heart Rate\" : np.array(data)})\n",
        "# df2.to_csv(\"/content/drive/MyDrive/ECG_data/hr_original_10.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-cQFHJz_Nrf"
      },
      "outputs": [],
      "source": [
        "plt.plot(x_g_AB[1])\n",
        "plt.plot(y_test[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PWaTgxKUEQg"
      },
      "outputs": [],
      "source": [
        "#X_test_in = []\n",
        "#x_g_AB_in = []\n",
        "#inverse differencing\n",
        "#for i in range(len(X_test)):\n",
        "#  X_test_in.append((np.concatenate(([X_test[i][0]], X_test[i])).cumsum())[:x_g_AB.shape[1]])\n",
        "#  x_g_AB_in.append((np.concatenate(([x_g_AB[i][0]], x_g_AB[i])).cumsum())[:x_g_AB.shape[1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvGRVswC-0aO"
      },
      "outputs": [],
      "source": [
        "# len(x_g_AB_in)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4v2SVaik_I2z"
      },
      "outputs": [],
      "source": [
        "# len(x_g_AB_in[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8CBh3HxUW1t"
      },
      "outputs": [],
      "source": [
        "# x_g_AB = np.array(x_g_AB_in).reshape(x_g_AB.shape[0],x_g_AB.shape[1],1)\n",
        "# X_test = np.array(X_test_in).reshape(X_test.shape[0],X_test.shape[1],1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPHBd5X9VDNy"
      },
      "outputs": [],
      "source": [
        "def smooth(x,window_len=7,window='hanning'):\n",
        "    \"\"\"smooth the data using a window with requested size.\n",
        "\n",
        "    This method is based on the convolution of a scaled window with the signal.\n",
        "    The signal is prepared by introducing reflected copies of the signal\n",
        "    (with the window size) in both ends so that transient parts are minimized\n",
        "    in the begining and end part of the output signal.\n",
        "\n",
        "    input:\n",
        "        x: the input signal\n",
        "        window_len: the dimension of the smoothing window; should be an odd integer\n",
        "        window: the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\n",
        "            flat window will produce a moving average smoothing.\n",
        "\n",
        "    output:\n",
        "        the smoothed signal\n",
        "\n",
        "    example:\n",
        "\n",
        "    t=linspace(-2,2,0.1)\n",
        "    x=sin(t)+randn(len(t))*0.1\n",
        "    y=smooth(x)\n",
        "\n",
        "    see also:\n",
        "\n",
        "    numpy.hanning, numpy.hamming, numpy.bartlett, numpy.blackman, numpy.convolve\n",
        "    scipy.signal.lfilter\n",
        "\n",
        "    TODO: the window parameter could be the window itself if an array instead of a string\n",
        "    NOTE: length(output) != length(input), to correct this: return y[(window_len/2-1):-(window_len/2)] instead of just y.\n",
        "    \"\"\"\n",
        "\n",
        "    if window_len<3:\n",
        "        return x\n",
        "\n",
        "    s=np.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
        "    #print(len(s))\n",
        "    if window == 'flat': #moving average\n",
        "        w=np.ones(window_len,'d')\n",
        "    else:\n",
        "        w=eval('np.'+window+'(window_len)')\n",
        "\n",
        "    y=np.convolve(w/w.sum(),s,mode='valid')\n",
        "    return y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FW-8-EYQZZF4"
      },
      "outputs": [],
      "source": [
        "x_g_AB_reshaped = x_g_AB.reshape(x_g_AB.shape[0],x_g_AB.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u163Y4jAZinu"
      },
      "outputs": [],
      "source": [
        "x_g_AB_reshaped.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6zBS52LTMKN"
      },
      "outputs": [],
      "source": [
        "x_g_AB_smoothed = []\n",
        "for i in range(len(x_g_AB_reshaped)):\n",
        "  smoothed = smooth(x_g_AB_reshaped[i])\n",
        "  x_g_AB_smoothed.append(smoothed[:len(x_g_AB_reshaped[i])])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrJEw9AjM2eI"
      },
      "outputs": [],
      "source": [
        "#          Testing functions\n",
        "#################################################################################\n",
        "def rmse(targets, predictions):\n",
        "    return np.sqrt(np.mean((targets-predictions)**2))\n",
        "\n",
        "\n",
        "def prd(targets, predictions):\n",
        "    s1 = np.sum((targets-predictions)**2)\n",
        "    s2 = np.sum(targets**2)\n",
        "    return np.sqrt(s1 / s2 * 100)\n",
        "\n",
        "\n",
        "def mmd(targets, predictions):\n",
        "    mmd_stat = MMDStatistic(400, 400)\n",
        "    sample_target = torch.from_numpy(targets.numpy().reshape((400,1)))\n",
        "    sample_pred = torch.from_numpy(predictions.numpy().reshape((400,1)))\n",
        "\n",
        "    stat = mmd_stat(sample_target, sample_pred, [1.])\n",
        "    return(stat.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxYLtf_JYGyZ"
      },
      "outputs": [],
      "source": [
        "x_g_AB_smoothed = np.array(x_g_AB_smoothed)\n",
        "x_g_AB_smoothed = x_g_AB_smoothed.reshape(x_g_AB_smoothed.shape[0],x_g_AB_smoothed.shape[1],1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWazhMXzrh8P"
      },
      "outputs": [],
      "source": [
        "y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0k8C5LdhrgP0"
      },
      "outputs": [],
      "source": [
        "x_g_AB_smoothed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCtZY8RUQtjf"
      },
      "outputs": [],
      "source": [
        "#for i in range(len(x_g_AB)):\n",
        "rmse_arr = rmse(y_test,x_g_AB)\n",
        "print(rmse_arr)\n",
        "rmse_smoothed = rmse(y_test,x_g_AB_smoothed)\n",
        "print(\"smoothed\",rmse_smoothed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6pV9wzdlTeS"
      },
      "outputs": [],
      "source": [
        "rmse_all =[]\n",
        "rmse_all_smoothened =[]\n",
        "for i in range(len(x_g_AB)):\n",
        "  rmse_all.append(rmse(y_test[i],x_g_AB[i]))\n",
        "  rmse_all_smoothened.append(rmse(y_test[i],x_g_AB_smoothed[i]))\n",
        "\n",
        "rmse_all_mean = np.array(rmse_all).mean()\n",
        "print(rmse_all_mean)\n",
        "rmse_all_smoothed_mean = np.array(rmse_all_smoothened).mean()\n",
        "print(\"smoothed\",rmse_all_smoothed_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wdDoH7eQ6Hh"
      },
      "outputs": [],
      "source": [
        "\n",
        "prd_arr = prd(y_test,x_g_AB)\n",
        "print(prd_arr)\n",
        "prd_arr_smoothed = prd(y_test,x_g_AB_smoothed)\n",
        "print(\"smoothed\",prd_arr_smoothed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHBGblEDuehI"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "mae_arr = mean_absolute_error(y_test.flatten(),x_g_AB.flatten())\n",
        "print(mae_arr)\n",
        "mae_arr_smoothed = mean_absolute_error(y_test.flatten(),x_g_AB_smoothed.flatten())\n",
        "print(\"smoothed\",mae_arr_smoothed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQVy4CB10gIT"
      },
      "outputs": [],
      "source": [
        "def detect_peaks(ecg_signal, threshold=0.3, qrs_filter=None):\n",
        "    '''\n",
        "    Peak detection algorithm using cross corrrelation and threshold\n",
        "    '''\n",
        "    if qrs_filter is None:\n",
        "        # create default qrs filter, which is just a part of the sine function\n",
        "        t = np.linspace(1.5 * np.pi, 3.5 * np.pi, 15)\n",
        "        qrs_filter = np.sin(t)\n",
        "\n",
        "    # normalize data\n",
        "    ecg_signal = (ecg_signal - ecg_signal.mean()) / ecg_signal.std()\n",
        "\n",
        "    # calculate cross correlation\n",
        "    similarity = np.correlate(ecg_signal, qrs_filter, mode=\"same\")\n",
        "    similarity = similarity / np.max(similarity)\n",
        "\n",
        "    # return peaks (values in ms) using threshold\n",
        "    return ecg_signal[similarity > threshold].index, similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sO0w_0O085l"
      },
      "outputs": [],
      "source": [
        "def group_peaks(p, threshold=5):\n",
        "    '''\n",
        "    The peak detection algorithm finds multiple peaks for each QRS complex.\n",
        "    Here we group collections of peaks that are very near (within threshold) and we take the median index\n",
        "    '''\n",
        "    # initialize output\n",
        "    output = np.empty(0)\n",
        "\n",
        "    # label groups of sample that belong to the same peak\n",
        "    peak_groups, num_groups = label(np.diff(p) < threshold)\n",
        "\n",
        "    # iterate through groups and take the mean as peak index\n",
        "    for i in np.unique(peak_groups)[1:]:\n",
        "        peak_group = p[np.where(peak_groups == i)]\n",
        "        output = np.append(output, np.median(peak_group))\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qW16tGB_5H12"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(x_g_AB.flatten(), columns = ['ECG'])\n",
        "df2 = pd.DataFrame(X_test.flatten(), columns = ['SCG'])\n",
        "df3 = pd.DataFrame(y_test.flatten(), columns = ['ECG_orig'])\n",
        "#df['column_name']=pd.Series(x_g_AB.flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yl2uDfgknydZ"
      },
      "outputs": [],
      "source": [
        "# n_samples = f.getNSamples()[0]\n",
        "\n",
        "# # Extract the signal data and flatten it\n",
        "# signal_data = f.readSignal(0).flatten()\n",
        "\n",
        "# # Close the file\n",
        "# f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XG1RQ-DoOSoy"
      },
      "outputs": [],
      "source": [
        "#!pip install wfdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7cR2ZpfPWQW"
      },
      "outputs": [],
      "source": [
        "import wfdb\n",
        "from wfdb import processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5u5zX8_aGcTm"
      },
      "outputs": [],
      "source": [
        "# to be used for wsdb to edf conversion and reading data using wsdb\n",
        "import wfdb\n",
        "from google.colab import files\n",
        "fileName_str\n",
        "record = wfdb.rdrecord('b009', pn_dir='cebsdb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tlWmRfQnsGt"
      },
      "outputs": [],
      "source": [
        "# # Get the number of channels and samples\n",
        "# n_channels = f.signals_in_file\n",
        "# n_samples = f.getNSamples()[0]\n",
        "\n",
        "# # Extract the signal data and flatten it\n",
        "# signal_data = f.readSignal(0).flatten()\n",
        "\n",
        "# # Close the file\n",
        "# f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKlovSfviNPG"
      },
      "outputs": [],
      "source": [
        "record.p_signal[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBWEowuanOEA"
      },
      "outputs": [],
      "source": [
        "# qrs = codeFn(ecg_signal, fs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEjBAFgSPcVf"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Demo 19 - Use the GQRS detection algorithm and correct the peaks\n",
        "\n",
        "def peaks_hr(sig, peak_inds, fs, title, figsize=(20, 10), saveto=None):\n",
        "    \"Plot a signal with its peaks and heart rate\"\n",
        "    # Calculate heart rate\n",
        "    hrs = processing.hr.compute_hr(sig_len=sig.shape[0], qrs_inds=peak_inds, fs=fs)\n",
        "    print(hrs)\n",
        "    N = sig.shape[0]\n",
        "\n",
        "    fig, ax_left = plt.subplots(figsize=figsize)\n",
        "    ax_right = ax_left.twinx()\n",
        "\n",
        "    ax_left.plot(sig, color='#3979f0', label='Signal')\n",
        "    ax_left.plot(peak_inds, sig[peak_inds], 'rx', marker='x',\n",
        "                 color='#8b0000', label='Peak', markersize=12)\n",
        "    ax_right.plot(np.arange(N), hrs, label='Heart rate', color='m', linewidth=2)\n",
        "\n",
        "    ax_left.set_title(title)\n",
        "\n",
        "    ax_left.set_xlabel('Time (ms)')\n",
        "    ax_left.set_ylabel('ECG (mV)', color='#3979f0')\n",
        "    ax_right.set_ylabel('Heart rate (bpm)', color='m')\n",
        "    # Make the y-axis label, ticks and tick labels match the line color.\n",
        "    ax_left.tick_params('y', colors='#3979f0')\n",
        "    ax_right.tick_params('y', colors='m')\n",
        "    if saveto is not None:\n",
        "        plt.savefig(saveto, dpi=600)\n",
        "    plt.show()\n",
        "    return hrs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2ZCHPZXoCxJ"
      },
      "outputs": [],
      "source": [
        "# t = np.arange(len(ecg_signal)) / fs\n",
        "# plt.plot(t, ecg_signal)\n",
        "# plt.plot(qrs/fs, ecg_signal[qrs], 'ro')\n",
        "# plt.xlabel('Time (s)')\n",
        "# plt.ylabel('ECG Amplitude')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OajguMORasOE"
      },
      "outputs": [],
      "source": [
        "# Load the WFDB record and the physical samples\n",
        "#record = wfdb.rdrecord('sample-data/100', sampfrom=0, sampto=10000, channels=[0])\n",
        "\n",
        "# Use the GQRS algorithm to detect QRS locations in the first channel\n",
        "qrs_inds = processing.qrs.gqrs_detect(sig=record.p_signal[:,0], fs=record.fs)\n",
        "\n",
        "# Plot results\n",
        "hrs = peaks_hr(sig=record.p_signal, peak_inds=qrs_inds, fs=record.fs,\n",
        "         title=\"GQRS peak detection on record b009\")\n",
        "\n",
        "# Correct the peaks shifting them to local maxima\n",
        "min_bpm = 20\n",
        "max_bpm = 230\n",
        "#min_gap = record.fs * 60 / min_bpm\n",
        "# Use the maximum possible bpm as the search radius\n",
        "search_radius = int(record.fs * 60 / max_bpm)\n",
        "corrected_peak_inds = processing.peaks.correct_peaks(record.p_signal[:,0],\n",
        "                                                     peak_inds=qrs_inds,\n",
        "                                                     search_radius=search_radius,\n",
        "                                                     smooth_window_size=150)\n",
        "\n",
        "# Display results\n",
        "print('Corrected GQRS detected peak indices:', sorted(corrected_peak_inds))\n",
        "hrs = peaks_hr(sig=record.p_signal, peak_inds=sorted(corrected_peak_inds), fs=record.fs,\n",
        "         title=\"Corrected GQRS peak detection on sampledata/100\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVKKF0h-LaTR"
      },
      "outputs": [],
      "source": [
        "# Load the WFDB record and the physical samples\n",
        "#record = wfdb.rdrecord('sample-data/100', sampfrom=0, sampto=10000, channels=[0])\n",
        "\n",
        "# Use the GQRS algorithm to detect QRS locations in the first channel\n",
        "qrs_inds = processing.qrs.gqrs_detect(sig=record.p_signal[:,3], fs=record.fs)\n",
        "\n",
        "# Plot results\n",
        "hrs_scg = peaks_hr(sig=record.p_signal, peak_inds=qrs_inds, fs=record.fs,\n",
        "         title=\"GQRS peak detection on record b009\")\n",
        "\n",
        "# Correct the peaks shifting them to local maxima\n",
        "min_bpm = 20\n",
        "max_bpm = 230\n",
        "#min_gap = record.fs * 60 / min_bpm\n",
        "# Use the maximum possible bpm as the search radius\n",
        "search_radius = int(record.fs * 60 / max_bpm)\n",
        "corrected_peak_inds = processing.peaks.correct_peaks(record.p_signal[:,3],\n",
        "                                                     peak_inds=qrs_inds,\n",
        "                                                     search_radius=search_radius,\n",
        "                                                     smooth_window_size=150)\n",
        "\n",
        "# Display results\n",
        "print('Corrected GQRS detected peak indices:', sorted(corrected_peak_inds))\n",
        "hrs_scg = peaks_hr(sig=record.p_signal, peak_inds=sorted(corrected_peak_inds), fs=record.fs,\n",
        "         title=\"Corrected GQRS peak detection on sampledata/100\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyrnU2HEV__r"
      },
      "outputs": [],
      "source": [
        "len(hrs)\n",
        "hrs = hrs[~np.isnan(hrs)]\n",
        "hrs=hrs[hrs<160]\n",
        "#hrs=hrs[hrs>100]\n",
        "print(len(hrs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DhtZiNIWGSP"
      },
      "outputs": [],
      "source": [
        "len(hrs_scg)\n",
        "\n",
        "hrs_scg = hrs_scg[~np.isnan(hrs_scg)]\n",
        "hrs_scg=hrs_scg[hrs_scg<160]\n",
        "#hrs_scg=hrs_scg[hrs_scg>100]\n",
        "print(len(hrs_scg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HsDwqZID_xZ"
      },
      "outputs": [],
      "source": [
        "# plotting the data\n",
        "plt.scatter(hrs[:len(hrs_scg)], hrs_scg)\n",
        "\n",
        "# This will fit the best line into the graph\n",
        "plt.plot(np.unique(hrs), np.poly1d(np.polyfit(hrs[:len(hrs_scg)], hrs_scg, 1))\n",
        "         (np.unique(hrs)), color='red')\n",
        "plt.ylabel(\"SCG heart rate\")\n",
        "plt.xlabel(\"ECG heart rate\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvedI0cjGOmL"
      },
      "outputs": [],
      "source": [
        "#!pip install pyhrv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0PTfIEd1MGa"
      },
      "outputs": [],
      "source": [
        "# detect peaks\n",
        "print(len(df.ECG))\n",
        "print(len(df2.SCG))\n",
        "print(len(df3.ECG_orig))\n",
        "peaks_ecg_pred, similarity = detect_peaks(df.ECG, threshold=0.3)\n",
        "peaks_scg, similarity = detect_peaks(df2.SCG, threshold=0.3)\n",
        "peaks_ecg, similarity = detect_peaks(df3.ECG_orig, threshold=0.3)\n",
        "\n",
        "print(len(peaks_ecg_pred))\n",
        "print(len(peaks_scg))\n",
        "print(len(peaks_ecg))\n",
        "# group peaks so we get a single peak per beat (hopefully)\n",
        "\n",
        "from scipy.ndimage import label\n",
        "grouped_peaks_ecg_pred = group_peaks(peaks_ecg_pred)\n",
        "grouped_peaks_scg = group_peaks(peaks_scg)\n",
        "grouped_peaks_ecg = group_peaks(peaks_ecg)\n",
        "\n",
        "print(len(grouped_peaks_ecg_pred))\n",
        "print(len(grouped_peaks_scg))\n",
        "print(len(grouped_peaks_ecg))\n",
        "# RR-intervals are the differences between successive peaks\n",
        "rr_ecg_pred = np.diff(grouped_peaks_ecg_pred)\n",
        "rr_scg = np.diff(grouped_peaks_scg)\n",
        "rr_ecg = np.diff(grouped_peaks_ecg)\n",
        "\n",
        "print(len(rr_ecg_pred))\n",
        "print(len(rr_scg))\n",
        "print(len(rr_ecg))\n",
        "# plot RR-intervals\n",
        "#plt.figure(figsize=(20, 7))\n",
        "#plt.title(\"RR-intervals\")\n",
        "#plt.xlabel(\"Time (ms)\")\n",
        "#plt.ylabel(\"RR-interval (ms)\")\n",
        "\n",
        "#plt.plot(np.cumsum(rr), rr, label=\"RR-interval\", color=\"#A651D8\")\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zdicn0_cI5tj"
      },
      "outputs": [],
      "source": [
        "\n",
        "from matplotlib.patches import Ellipse\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hM98N4hTIhbL"
      },
      "outputs": [],
      "source": [
        "def plot_poincare(rr):\n",
        "    rr_n = rr[:-1]\n",
        "    rr_n1 = rr[1:]\n",
        "\n",
        "    sd1 = np.sqrt(0.5) * np.std(rr_n1 - rr_n)\n",
        "    sd2 = np.sqrt(0.5) * np.std(rr_n1 + rr_n)\n",
        "\n",
        "    m = np.mean(rr)\n",
        "    min_rr = np.min(rr)\n",
        "    max_rr = np.max(rr)\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.title(\"Poincare plot\")\n",
        "\n",
        "    sns.scatterplot(x=rr_n, y=rr_n1, color=\"#51A6D8\")\n",
        "\n",
        "    plt.xlabel(r'$RR_n (ms)$')\n",
        "    plt.ylabel(r'$RR_{n+1} (ms)$')\n",
        "\n",
        "    e1 = Ellipse((m, m), 2*sd1, 2*sd2, angle=-45, linewidth=1.2, fill=False, color=\"k\")\n",
        "    plt.gca().add_patch(e1)\n",
        "\n",
        "    plt.arrow(m, m, (max_rr-min_rr)*0.4, (max_rr-min_rr)*0.4, color=\"k\", linewidth=0.8, head_width=5, head_length=5)\n",
        "    plt.arrow(m, m, (min_rr-max_rr)*0.4, (max_rr-min_rr)*0.4, color=\"k\", linewidth=0.8, head_width=5, head_length=5)\n",
        "\n",
        "    plt.arrow(m, m, sd2 * np.sqrt(0.5), sd2 * np.sqrt(0.5), color=\"green\", linewidth=5)\n",
        "    plt.arrow(m, m, -sd1 * np.sqrt(0.5), sd1 * np.sqrt(0.5), color=\"red\", linewidth=5)\n",
        "\n",
        "    plt.text(max_rr, max_rr, \"SD2\", fontsize=20, color=\"green\")\n",
        "    plt.text(m-(max_rr-min_rr)*0.4-20, max_rr, \"SD1\", fontsize=20, color=\"red\")\n",
        "\n",
        "    return sd1, sd2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XtMdphUInOn"
      },
      "outputs": [],
      "source": [
        "sd1, sd2 = plot_poincare(rr_ecg_pred)\n",
        "print(\"SD1: %.3f ms\" % sd1)\n",
        "print(\"SD2: %.3f ms\" % sd2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9RogA2aBkBl"
      },
      "outputs": [],
      "source": [
        "sd1, sd2 = plot_poincare(rr_scg)\n",
        "print(\"SD1: %.3f ms\" % sd1)\n",
        "print(\"SD2: %.3f ms\" % sd2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcMUKpkBGcVP"
      },
      "outputs": [],
      "source": [
        "import pyhrv\n",
        "pyhrv.nonlinear.poincare(rr_ecg_pred,peaks_ecg_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cq7uWKlkv5YL"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import pearsonr\n",
        "true = y_test.astype('float')\n",
        "pre =  x_g_AB.astype('float')\n",
        "corr, pval =pearsonr(true.flatten(),pre.flatten())\n",
        "print(\"corre and p-val:: \",corr, pval)\n",
        "\n",
        "\n",
        "pre_smoothed =  x_g_AB_smoothed.astype('float')\n",
        "corr_sm, pval_sm =pearsonr(true.flatten(),pre_smoothed.flatten())\n",
        "print(\"smoothed corre and p-val:: \",corr_sm, pval_sm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzA3hVXVKqvG"
      },
      "outputs": [],
      "source": [
        "accuracy_for_AtoB = 100 - (np.mean(np.abs(x_g_AB-y_test)*100))\n",
        "print(accuracy_for_AtoB)\n",
        "\n",
        "accuracy_for_AtoB_sm = 100 - (np.mean(np.abs(x_g_AB_smoothed-y_test)*100))\n",
        "print(\"smoothed\",accuracy_for_AtoB_sm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zJcNkEDIeWj"
      },
      "outputs": [],
      "source": [
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.dpi'] = 300\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiGoXcO2HLNl"
      },
      "outputs": [],
      "source": [
        "print(len(str(fileNames[0]))-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rz4ZFn5UxcS"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# fig = plt.figure(figsize=(4,3))\n",
        "# fig.set_size_inches(50,7)\n",
        "# plt.plot(y_test.flatten()[:5000],color=\"blue\")\n",
        "# plt.plot(np.array(x_g_AB).flatten()[:5000], color=\"red\")\n",
        "# plt.show()\n",
        "# fig.savefig('/content/drive/MyDrive/Colab Notebooks/basal/b_to_b_'+str(fileNames[0])[0:len(str(fileNames[0]))-4]+'_first_5000.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqQmbihI3VFj"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# fig = plt.figure(figsize=(4,3))\n",
        "# fig.set_size_inches(50,7)\n",
        "# plt.plot(y_test.flatten()[:5000],color=\"blue\")\n",
        "# # plt.plot(np.array(x_g_AB).flatten()[:5000], color=\"red\")\n",
        "# plt.show()\n",
        "# fig.savefig('/content/drive/MyDrive/Colab Notebooks/basal/b_to_b_'+str(fileNames[0])[0:len(str(fileNames[0]))-4]+'_blue.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nOF_7Vg5p6z"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# fig = plt.figure(figsize=(4,3))\n",
        "# fig.set_size_inches(50,7)\n",
        "# # plt.plot(y_test.flatten()[:5000],color=\"blue\")\n",
        "# plt.plot(np.array(x_g_AB).flatten()[:5000], color=\"red\")\n",
        "# plt.show()\n",
        "# fig.savefig('/content/drive/MyDrive/Colab Notebooks/basal/b_to_b_'+str(fileNames[0])[0:len(str(fileNames[0]))-4]+'_red.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccpSirZgbL7O"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# fig = plt.figure(figsize=(4,3))\n",
        "# fig.set_size_inches(50,7)\n",
        "# plt.plot(y_test.flatten()[:5000],color=\"blue\")\n",
        "# plt.plot(np.array(x_g_AB_smoothed).flatten()[:5000], color=\"red\")\n",
        "# plt.show()\n",
        "# fig.savefig('/content/drive/MyDrive/Colab Notebooks/basal/b_to_b_'+str(fileNames[0])[0:len(str(fileNames[0]))-4]+'_first_5000_smoothed.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9BydaDI51Dr"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# fig = plt.figure(figsize=(4,3))\n",
        "# fig.set_size_inches(50,7)\n",
        "# plt.plot(y_test.flatten()[:5000],color=\"blue\")\n",
        "# # plt.plot(np.array(x_g_AB_smoothed).flatten()[:5000], color=\"red\")\n",
        "# plt.show()\n",
        "# fig.savefig('/content/drive/MyDrive/Colab Notebooks/basal/b_to_b_'+str(fileNames[0])[0:len(str(fileNames[0]))-4]+'_blue_smoothed.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwXrm5MH6Idu"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# fig = plt.figure(figsize=(4,3))\n",
        "# fig.set_size_inches(50,7)\n",
        "# # plt.plot(y_test.flatten()[:5000],color=\"blue\")\n",
        "# plt.plot(np.array(x_g_AB_smoothed).flatten()[:5000], color=\"red\")\n",
        "# plt.show()\n",
        "# fig.savefig('/content/drive/MyDrive/Colab Notebooks/basal/b_to_b_'+str(fileNames[0])[0:len(str(fileNames[0]))-4]+'_red_smoothed.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSjZzZUsVD_x"
      },
      "outputs": [],
      "source": [
        "# for i in range(len(y_test)):\n",
        "#   fig = plt.figure(figsize=(4,3))\n",
        "#   fig.set_size_inches(50,7)\n",
        "#   plt.plot(y_test[i],color=\"blue\")\n",
        "#   plt.plot(x_g_AB[i], color=\"red\")\n",
        "#   plt.show()\n",
        "#   plt.savefig('/content/drive/MyDrive/Colab Notebooks/GAN_PAPER_DATA/basal/b_to_b_1_batch_'+str(i+1)+'.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Mb0GpQobaAR"
      },
      "outputs": [],
      "source": [
        "# for i in range(len(y_test)):\n",
        "#   fig = plt.figure(figsize=(4,3))\n",
        "#   fig.set_size_inches(50,7)\n",
        "#   plt.plot(y_test[i],color=\"blue\")\n",
        "#   plt.plot(x_g_AB_smoothed[i], color=\"red\")\n",
        "#   plt.savefig('/content/drive/MyDrive/Colab Notebooks/GAN_PAPER_DATA/basal/b_to_b_1_smoothed_batch_'+str(i+1)+'.jpg')\n",
        "#   plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8R4embaispm9"
      },
      "outputs": [],
      "source": [
        "# !pip install frechetdist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsD1i3QNcs_a"
      },
      "outputs": [],
      "source": [
        "# import sys\n",
        "# print(sys.getrecursionlimit())\n",
        "# sys.setrecursionlimit(5000)\n",
        "# print(sys.getrecursionlimit())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtiJpcXEnjc6"
      },
      "outputs": [],
      "source": [
        "# from frechetdist import frdist\n",
        "# fd = []\n",
        "# for i in range(len(y_test)):\n",
        "#   fd.append(frdist(y_test[i],x_g_AB[i]))\n",
        "# print(\"FD: \", np.array(fd).mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mapGaw0HvhHa"
      },
      "outputs": [],
      "source": [
        "\n",
        "#mmd_arr = mmd(y_test,x_g_AB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FME3FqsWtliD"
      },
      "outputs": [],
      "source": [
        "# fd_mean = np.array(fd).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqyCpTSVntXV"
      },
      "outputs": [],
      "source": [
        "#To create the blank csv with header.\n",
        "\n",
        "#from csv import writer\n",
        "\n",
        "#List=[\"Subject\",\"Generator param A\", \"Generator param B\",\"Reconstructor param A\",\"Reconstructor param B\",\"RMSE flattened\", \"RMSE Smoothed flattened\",\"RMSE All Mean\", \"RMSE All Smoothed Mean\", \"prd\", \"prd smoothed\",\"mae\",\"mae smoothed\", \"correlation\",\"correlation smoothed\",\"p-val\",\"p-val smoothed\",\"accuracy\",\"accuracy smoothed\",\"frachet dist\"]\n",
        "\n",
        "#with open('/content/drive/MyDrive/Colab Notebooks/GAN_PAPER_DATA/basal/matrices.csv', 'w') as f_object:\n",
        "\n",
        "#    writer_object = writer(f_object)\n",
        "#    writer_object.writerow(List)\n",
        "\n",
        "#    f_object.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tBmFw4I12-y"
      },
      "outputs": [],
      "source": [
        "# change the parameters here\n",
        "gen_param_a = 0\n",
        "gen_param_b = 0\n",
        "rec_param_a = 0\n",
        "rec_param_b = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CW92FBJMs1rq"
      },
      "outputs": [],
      "source": [
        "# List\n",
        "List_vals =[fileNames[0], gen_param_a,gen_param_b,rec_param_a,rec_param_b, rmse_arr, rmse_smoothed, rmse_all_mean, rmse_all_smoothed_mean, prd_arr, prd_arr_smoothed,mae_arr,mae_arr_smoothed, corr,corr_sm,pval,pval_sm,accuracy_for_AtoB,accuracy_for_AtoB_sm]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYk_0-G-t3sX"
      },
      "outputs": [],
      "source": [
        "\n",
        "# from csv import writer\n",
        "\n",
        "# with open('/content/drive/MyDrive/Colab Notebooks/basal/matrices.csv', 'a') as f_object:\n",
        "\n",
        "#     writer_object = writer(f_object)\n",
        "#     writer_object.writerow(List_vals)\n",
        "\n",
        "#     f_object.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSqpdHYCJA8y"
      },
      "outputs": [],
      "source": [
        "# !pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_Xg6pwAiY4h"
      },
      "outputs": [],
      "source": [
        "# !pip install -c dloewenstein torch-two-sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aH-uFRmJZm5"
      },
      "outputs": [],
      "source": [
        "#!pip install mmd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q90eindpKZ7G"
      },
      "outputs": [],
      "source": [
        "# !pip install torch torchvision\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S733gBm7Qrx5"
      },
      "outputs": [],
      "source": [
        "# from torch_two_sample.statistics_diff import MMDStatistic\n",
        "# print(mmd(y_test,x_g_AB))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X75GyDycKd0j"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kV3DzxzNGsdJ"
      },
      "outputs": [],
      "source": [
        "#!pip install ecg_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPx2jXZawBbP"
      },
      "outputs": [],
      "source": [
        "#import ecg_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnC5ZOPVo6yi"
      },
      "outputs": [],
      "source": [
        "#for i in range(10):\n",
        "#  ecg_plot.plot_1(y_test_scaled[i], sample_rate=500, title = 'Original ECG')\n",
        " # ecg_plot.plot_1(x_g_AB_scaled[i], sample_rate=500, title = 'Predicted ECG')\n",
        "  #plt.tight_layout()\n",
        " # ecg_plot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jt7WsGomHyAD"
      },
      "outputs": [],
      "source": [
        "\n",
        "#ecg_plot.plot_1(y_test.flatten(), sample_rate=1000, title = 'Original')\n",
        "#ecg_plot.plot_1(x_g_AB.flatten(), sample_rate=1000, title = 'Predicted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNUu09O8WhX3"
      },
      "outputs": [],
      "source": [
        "#x = y_test[0].flatten().tolist()\n",
        "#y = x_g_AB[0].flatten().tolist()\n",
        "#for i in range(len(x_g_AB)):\n",
        "#  x.append((y_test[i][len(y_test[i])-1])[0])\n",
        "#  y.append((x_g_AB[i][len(x_g_AB[i])-1])[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qr7ofa2xOc49"
      },
      "outputs": [],
      "source": [
        "print(\"acc: %3d%%\"% accuracy_for_AtoB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ux9A5BOdPNZD"
      },
      "outputs": [],
      "source": [
        "# normalize correlation\n",
        "a = (y_test - np.mean(y_test)) / (np.std(y_test) * len(y_test))\n",
        "b = (x_g_AB - np.mean(x_g_AB)) / (np.std(x_g_AB))\n",
        "c = np.correlate(a.flatten(), b.flatten(), 'full')\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVfrUH2l_X3o"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "mse = mean_squared_error(y_test.flatten(), x_g_AB.flatten())\n",
        "print(mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SuBwpYd_oO_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "mae = mean_absolute_error(y_test.flatten(), x_g_AB.flatten())\n",
        "print(mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aE1VHpvD0-AH"
      },
      "outputs": [],
      "source": [
        "y_pred = x_g_AB.flatten()\n",
        "y_test_new = y_test.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zs64HmthxRFs"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_pred[y_pred > 0.5] = 1\n",
        "y_pred[y_pred <= 0.5] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mn6Cv1P9xo49"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_test_new[y_test_new > 0.5] = 1\n",
        "y_test_new[y_test_new <= 0.5] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2cFEBwO_8Wo"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score,accuracy_score,recall_score,precision_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ailUHhBooDXO"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"accuracy_score\",accuracy_score(y_test_new, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwTBJos0zUAz"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"precision_score\",precision_score(y_test_new, y_pred , pos_label='positive', average='micro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUaN4GV2xig6"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"f1_score\",f1_score(y_test_new, y_pred, pos_label='positive', average='micro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lxidi8ZXxlpA"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"recall_score\",recall_score(y_test_new, y_pred, pos_label='positive', average='micro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAC5ojYUxnmy"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "a = [1,1,1,1,1,0]\n",
        "b=[1,1,1,1,0,0]\n",
        "matrix = confusion_matrix(y_test_new, y_pred)\n",
        "print(matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BIF5Y8gC2-v"
      },
      "outputs": [],
      "source": [
        "# correlation coefficient r of x and y\n",
        "from scipy import stats\n",
        "slope, intercept, r_value, p_value, std_err = stats.linregress(y_test_new, y_pred)\n",
        "print (r_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnqyx3KsDERn"
      },
      "outputs": [],
      "source": [
        "# The coefficient of determination\n",
        "from sklearn.metrics import r2_score\n",
        "print(r2_score(y_test_new, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWtT4BLEvIQK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}